{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rypotter/depo/blob/master/Ollama_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Ollama and Langchain"
      ],
      "metadata": {
        "id": "3unUffJd0Vx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "SF1YeP7CxUjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start Ollama server as a background process and pull llama3 image."
      ],
      "metadata": {
        "id": "klts3IEj0k2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "process = subprocess.Popen([\"ollama\", \"serve\"])"
      ],
      "metadata": {
        "id": "Z24oORsrye_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1Zdzf12zC3u",
        "outputId": "87ba6881-97dd-4129-993f-479e8704c096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME\tID\tSIZE\tMODIFIED \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull llama3"
      ],
      "metadata": {
        "id": "7QLGgGRHyNGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expose the port"
      ],
      "metadata": {
        "id": "9E4oSvSv1Hkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.output import eval_js\n",
        "notebook_url = eval_js(\"google.colab.kernel.proxyPort(11434)\")"
      ],
      "metadata": {
        "id": "yvUaZUvFxUrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export OLLAMA_HOST=notebook_url"
      ],
      "metadata": {
        "id": "1YWw8UysxUuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Ollama\n",
        "llm = Ollama(model=\"llama3\")"
      ],
      "metadata": {
        "id": "jXCxVp85x2_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%timeit\n",
        "response = llm.invoke(\"Tell me a joke\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ilTlOFEx3CX",
        "outputId": "dbb63c31-68bf-45e3-f57f-4879989f8d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's one:\n",
            "\n",
            "Why couldn't the bicycle stand up by itself?\n",
            "\n",
            "(wait for it...)\n",
            "\n",
            "Because it was two-tired!\n",
            "\n",
            "Hope that made you laugh!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t0i8BTbU1shz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NDOGFb981q9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}